性能调优，大部分时候想要实现的目标是让我们的查询更快。一个查询的 动作又是由很多个环节组成的，每个环节都会消耗时间。


我们要减少查询所消耗的时间，就要从每一个环节入手。


- 连接——配置优化

第一个环节是客户端连接到服务端，连接这一块有可能会出现什么样的性能问题? 有可能是服务端连接数不够导致应用程序获取不到连接。比如报了一个 Mysql: error 1040: Too many connections 的错误。

1. 从服务端来说，我们可以增加服务端的可用连接数。

    修改配置参数增加可用连接数，修改 max_connections 的大小:
    ```mysql
    show variables like 'max_connections'; 
    -- 修改最大连接数，当有多个应用连接的时候
    ```

    或者及时释放不活动的连接。交互式和非交互式的客户端的默认超时时
间都是 28800 秒，8 小时，我们可以把这个值调小。

    ```mysql
    show global variables like 'wait_timeout'; 
    --及时释放不活动的连接，注意不要释放连接池还在使用的连接
    ```

2. 从客户端来说，可以减少从服务端获取的连接数，如果我们想要不是每一次执行 SQL 都创建一个新的连接，应该怎么做?

    这个时候我们可以引入连接池，实现连接的重用。

    连接池的大小应该怎么设置呢?

    连接池并不是越大越好，只要维护一定数量大小的连接池， 其他的客户端排队等待获取连接就可以了。有的时候连接池越大，效率反而越低。
Druid 的默认最大连接池大小是 8。Hikari 的默认最大连接池大小是 10。

    ### 为什么默认值都是这么小呢?

    在 Hikari 的 github 文档中，给出了一个 PostgreSQL 数据库建议的设置连接池大小的公式:[地址](https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing)

    它的建议是机器核数乘以 2 加 1。也就是说，4 核的机器，连接池维护 9 个连接就 够了。这个公式从一定程度上来说对其他数据库也是适用的。这里面还有一个减少连接 池大小实现提升并发度和吞吐量的案例。

    ### 为什么有的情况下，减少连接数反而会提升吞吐量呢?为什么建议设置的连接池大 小要跟 CPU 的核数相关呢?

    每一个连接，服务端都需要创建一个线程去处理它。连接数越多，服务端创建的线程数就会越多。

    ### CPU 是怎么同时执行远远超过它的核数大小的任务的?时间片。
    
    上下文切换。 而 CPU 的核数是有限的，频繁的上下文切换会造成比较大的性能开销。

- 缓存

    在应用系统的并发数非常大的情况下，如果没有缓存，会造成两个问题:一方面是 会给数据库带来很大的压力。另一方面，从应用的层面来说，操作数据的速度也会受到 影响。

    我们可以用第三方的缓存服务来解决这个问题，例如 Redis。


- 主从复制

    如果单台数据库服务满足不了访问需求，那我们可以做数据库的集群方案。

    ### 集群的话必然会面临一个问题，就是不同的节点之间数据一致性的问题。如果同时 读写多台数据库节点，怎么让所有的节点数据保持一致?

    >这个时候我们需要用到复制技术(replication)，被复制的节点称为 master，复制 的节点称为 slave。slave 本身也可以作为其他节点的数据来源，这个叫做级联复制。

    ### 主从复制是怎么实现的呢?更新语句会记录 binlog，它是一种逻辑日志。

    >有了这个 binlog，从服务器会获取主服务器的 binlog 文件，然后解析里面的 SQL 语句，在从服务器上面执行一遍，保持主从的数据一致。

    >这里面涉及到三个线程，连接到 master 获取 binlog，并且解析 binlog 写入中继日 志，这个线程叫做 I/O 线程。

    >Master 节点上有一个 log dump 线程，是用来发送 binlog 给 slave 的。 
    
    > 从库的 SQL 线程，是用来读取 relay log，把数据写入到数据库的。

    ![image](http://java-run-blog.oss-cn-zhangjiakou.aliyuncs.com/a2d2da7d1d3c4ec4ac4fc36a769c72dd.png
)